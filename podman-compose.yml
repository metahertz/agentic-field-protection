version: '3.8'

services:
  ollama:
    build:
      context: .
      dockerfile: Containerfile.ollama
    container_name: ollama
    hostname: ollama
    ports:
      - "11434:11434"
    volumes:
      - ${OLLAMA_MODEL_STORAGE:-ollama-data}:/root/.ollama
    environment:
      - OLLAMA_HOST=0.0.0.0:11434
      - OLLAMA_NUM_PARALLEL=${OLLAMA_NUM_PARALLEL:-1}
      - OLLAMA_MAX_LOADED_MODELS=${OLLAMA_MAX_LOADED_MODELS:-1}
    devices:
      - /dev/dri:/dev/dri  # GPU access
    restart: unless-stopped
    networks:
      - llm-network

  openwebui:
    build:
      context: .
      dockerfile: Containerfile.openwebui
    container_name: openwebui
    hostname: openwebui
    ports:
      - "${OPENWEBUI_PORT:-8080}:8080"
    volumes:
      - ${OPENWEBUI_DATA_STORAGE:-openwebui-data}:/app/backend/data
    environment:
      - OLLAMA_BASE_URL=http://ollama:11434
      - WEBUI_AUTH=${WEBUI_AUTH:-false}
      - ENABLE_OLLAMA_API=true
    depends_on:
      - ollama
    restart: unless-stopped
    networks:
      - llm-network

  mcp:
    build:
      context: .
      dockerfile: Containerfile.mcp
    container_name: mcp-mongodb
    hostname: mcp
    ports:
      - "${MCP_PORT:-3000}:3000"
    volumes:
      - ./mcp-config.json:/app/config/mcp-config.json:ro
    environment:
      - MONGODB_URI=${MONGODB_URI}
      - MCP_LOG_LEVEL=${MCP_LOG_LEVEL:-info}
      - NODE_ENV=production
    secrets:
      - mongodb_uri
    restart: unless-stopped
    networks:
      - llm-network

volumes:
  ollama-data:
    driver: local
  openwebui-data:
    driver: local

secrets:
  mongodb_uri:
    file: ${MONGODB_URI_FILE:-secrets/mongodb_uri}

networks:
  llm-network:
    driver: bridge
