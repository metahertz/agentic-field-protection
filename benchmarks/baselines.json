{
  "version": "1.0.0",
  "description": "Benchmark baselines for performance regression testing",
  "models": {
    "llama3.2:3b": {
      "description": "Llama 3.2 3B - default model",
      "token_generation": {
        "gpu": {
          "min_tokens_per_sec": 40,
          "max_tokens_per_sec": 100,
          "description": "Podman GPU passthrough (Vulkan/Metal)"
        },
        "cpu": {
          "min_tokens_per_sec": 5,
          "max_tokens_per_sec": 20,
          "description": "CPU-only inference"
        }
      },
      "prompt_processing": {
        "gpu": {
          "min_tokens_per_sec": 100,
          "max_tokens_per_sec": 500
        },
        "cpu": {
          "min_tokens_per_sec": 20,
          "max_tokens_per_sec": 100
        }
      }
    },
    "llama3.2:1b": {
      "description": "Llama 3.2 1B - lightweight model",
      "token_generation": {
        "gpu": {
          "min_tokens_per_sec": 60,
          "max_tokens_per_sec": 150,
          "description": "Podman GPU passthrough (Vulkan/Metal)"
        },
        "cpu": {
          "min_tokens_per_sec": 10,
          "max_tokens_per_sec": 40,
          "description": "CPU-only inference"
        }
      },
      "prompt_processing": {
        "gpu": {
          "min_tokens_per_sec": 150,
          "max_tokens_per_sec": 600
        },
        "cpu": {
          "min_tokens_per_sec": 40,
          "max_tokens_per_sec": 150
        }
      }
    },
    "llama3.1:8b": {
      "description": "Llama 3.1 8B - larger model",
      "token_generation": {
        "gpu": {
          "min_tokens_per_sec": 25,
          "max_tokens_per_sec": 70,
          "description": "Podman GPU passthrough (Vulkan/Metal)"
        },
        "cpu": {
          "min_tokens_per_sec": 3,
          "max_tokens_per_sec": 12,
          "description": "CPU-only inference"
        }
      },
      "prompt_processing": {
        "gpu": {
          "min_tokens_per_sec": 80,
          "max_tokens_per_sec": 350
        },
        "cpu": {
          "min_tokens_per_sec": 15,
          "max_tokens_per_sec": 70
        }
      }
    }
  },
  "thresholds": {
    "regression_tolerance_pct": 15,
    "description": "Results below (min - tolerance%) are flagged as regressions"
  }
}
